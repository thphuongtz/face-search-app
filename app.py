import streamlit as st
import torch
from facenet_pytorch import MTCNN, InceptionResnetV1
from PIL import Image
import numpy as np
import faiss
import os
from FAISS import build_faiss_index
import matplotlib.pyplot as plt

# --- Cáº¥u hÃ¬nh ---
DB_PATH = "database"
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# --- Khá»Ÿi táº¡o MTCNN vÃ  ResNet ---
mtcnn = MTCNN(image_size=160, margin=0, keep_all=False, post_process=True, device=device)
resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)

# --- HÃ m váº½ so sÃ¡nh 20 vector Ä‘áº§u tiÃªn ---
def plot_embedding_comparison(query_emb, matched_emb):
    fig, ax = plt.subplots()
    x = np.arange(20)
    ax.plot(x, query_emb[:20], label='áº¢nh truy váº¥n', marker='o')
    ax.plot(x, matched_emb[:20], label='áº¢nh database', marker='x')
    ax.set_title("So sÃ¡nh 20 vector Ä‘áº·c trÆ°ng Ä‘áº§u tiÃªn")
    ax.set_xlabel("Chá»‰ sá»‘ vector")
    ax.set_ylabel("GiÃ¡ trá»‹")
    ax.legend()
    st.pyplot(fig)

# --- Chuáº©n bá»‹ database ---
os.makedirs(DB_PATH, exist_ok=True)
image_files = [os.path.join(DB_PATH, f) for f in os.listdir(DB_PATH)
               if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
if not image_files:
    st.error("âš ï¸ ThÆ° má»¥c database trá»‘ng â€” hÃ£y thÃªm áº£nh máº«u vÃ o.")
    st.stop()

index, filenames = build_faiss_index(image_files)
st.success(f"âœ… ÄÃ£ táº£i {len(filenames)} áº£nh trong database!")

# --- Giao diá»‡n ---
st.title("ğŸ¤– Nháº­n diá»‡n khuÃ´n máº·t tá»± Ä‘á»™ng (2 áº£nh crop)")

mode = st.radio("Chá»n nguá»“n áº£nh:", ["ğŸ“¸ Webcam", "ğŸ“ Táº£i áº£nh tá»« file"])

if mode == "ğŸ“¸ Webcam":
    st.info("ğŸ§  Há»‡ thá»‘ng sáº½ nháº­n diá»‡n khuÃ´n máº·t sau khi chá»¥p.")
    img_data = st.camera_input("Báº­t webcam Ä‘á»ƒ chá»¥p áº£nh")
    if img_data:
        img = Image.open(img_data).convert("RGB")

elif mode == "ğŸ“ Táº£i áº£nh tá»« file":
    uploaded_file = st.file_uploader("Chá»n áº£nh Ä‘á»ƒ nháº­n diá»‡n", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        img = Image.open(uploaded_file).convert("RGB")
else:
    img = None

# --- Xá»­ lÃ½ ---
if 'img' in locals():
    boxes, probs, _ = mtcnn.detect(img, landmarks=True)
    if boxes is None:
        st.error("âŒ KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c khuÃ´n máº·t!")
        st.stop()

    # Cáº¯t khuÃ´n máº·t truy váº¥n
    x1, y1, x2, y2 = boxes[0]
    query_face = img.crop((x1, y1, x2, y2)).resize((160, 160))

    # TÃ­nh embedding
    face_tensor = torch.tensor(np.array(query_face)).permute(2, 0, 1).float() / 255.0
    face_tensor = (face_tensor.unsqueeze(0).to(device) * 2) - 1
    query_emb = resnet(face_tensor).detach().cpu().numpy().flatten()

    # TÃ¬m áº£nh database khá»›p nháº¥t
    D, I = index.search(query_emb.astype('float32').reshape(1, -1), 1)
    matched_path = filenames[I[0][0]]
    distance = float(D[0][0])
    person_name = os.path.splitext(os.path.basename(matched_path))[0]
    threshold = 0.9

    # Cáº¯t khuÃ´n máº·t trong database
    db_img = Image.open(matched_path).convert("RGB")
    db_boxes, _, _ = mtcnn.detect(db_img)
    if db_boxes is not None:
        x1, y1, x2, y2 = db_boxes[0]
        matched_face = db_img.crop((x1, y1, x2, y2)).resize((160, 160))
    else:
        matched_face = db_img.resize((160, 160))

    # Embedding DB Ä‘á»ƒ so sÃ¡nh vector
    matched_tensor = torch.tensor(np.array(matched_face)).permute(2, 0, 1).float() / 255.0
    matched_tensor = (matched_tensor.unsqueeze(0).to(device) * 2) - 1
    matched_emb = resnet(matched_tensor).detach().cpu().numpy().flatten()

    # --- Hiá»ƒn thá»‹ ---
    col1, col2 = st.columns(2)
    with col1:
        st.image(query_face, caption="ğŸ“¸ áº¢nh truy váº¥n", width=200)
    with col2:
        st.image(matched_face, caption=f"ğŸ§  áº¢nh trong database ({person_name})", width=200)

    # --- Káº¿t quáº£ ---
    if distance < threshold:
        st.success(f"âœ… Khá»›p vá»›i **{person_name}** (Khoáº£ng cÃ¡ch: {distance:.4f})")
    else:
        st.warning(f"âš ï¸ KhÃ´ng khá»›p vá»›i ai trong database (Khoáº£ng cÃ¡ch: {distance:.4f})")

    # --- So sÃ¡nh vector ---
    plot_embedding_comparison(query_emb, matched_emb)
