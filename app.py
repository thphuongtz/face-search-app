import streamlit as st
import torch
from facenet_pytorch import MTCNN, InceptionResnetV1
from PIL import Image, ImageDraw
import numpy as np
import faiss
import os
from FAISS import build_faiss_index
import matplotlib.pyplot as plt

# --- Cáº¥u hÃ¬nh ---
DB_PATH = "database"
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# --- Khá»Ÿi táº¡o MTCNN vÃ  ResNet ---
mtcnn = MTCNN(image_size=160, margin=0, keep_all=False, post_process=True, device=device)
resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)

# --- HÃ m váº½ landmarks ---
def show_face_with_landmarks(img, landmarks):
    img_copy = img.copy()
    draw = ImageDraw.Draw(img_copy)
    if landmarks is not None:
        for (x, y) in landmarks.astype(int):
            r = 2
            draw.ellipse((x - r, y - r, x + r, y + r), fill=(255, 0, 0))
    return img_copy

# --- HÃ m váº½ so sÃ¡nh 20 vector Ä‘áº§u tiÃªn ---
def plot_embedding_comparison(query_emb, matched_emb):
    fig, ax = plt.subplots()
    x = np.arange(20)
    ax.plot(x, query_emb[:20], label='Query', marker='o')
    ax.plot(x, matched_emb[:20], label='Matched', marker='x')
    ax.set_title("So sÃ¡nh 20 vector Ä‘áº·c trÆ°ng Ä‘áº§u tiÃªn")
    ax.set_xlabel("Index vector")
    ax.set_ylabel("GiÃ¡ trá»‹ embedding")
    ax.legend()
    st.pyplot(fig)

# --- Chuáº©n bá»‹ database ---
os.makedirs(DB_PATH, exist_ok=True)
image_files = [os.path.join(DB_PATH, f) for f in os.listdir(DB_PATH)
               if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
if not image_files:
    st.error("âš ï¸ ThÆ° má»¥c database trá»‘ng â€” hÃ£y thÃªm áº£nh máº«u vÃ o.")
    st.stop()

index, filenames = build_faiss_index(image_files)
st.success(f"âœ… ÄÃ£ táº£i {len(filenames)} áº£nh trong database!")

# --- Giao diá»‡n ---
st.title("ğŸ¥ Nháº­n diá»‡n khuÃ´n máº·t tá»± Ä‘á»™ng")

mode = st.radio("Chá»n nguá»“n áº£nh:", ["ğŸ“¸ Webcam", "ğŸ“ Táº£i áº£nh tá»« file"])

if mode == "ğŸ“¸ Webcam":
    st.info("ğŸ§  Há»‡ thá»‘ng sáº½ tá»± nháº­n diá»‡n khuÃ´n máº·t ngay sau khi chá»¥p.")
    img_data = st.camera_input("Báº­t webcam Ä‘á»ƒ chá»¥p tá»± Ä‘á»™ng")

    if img_data:
        img = Image.open(img_data).convert("RGB")

elif mode == "ğŸ“ Táº£i áº£nh tá»« file":
    uploaded_file = st.file_uploader("Chá»n áº£nh Ä‘á»ƒ nháº­n diá»‡n", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        img = Image.open(uploaded_file).convert("RGB")

else:
    img = None

# --- Xá»­ lÃ½ áº£nh (náº¿u cÃ³) ---
if 'img' in locals():
    # PhÃ¡t hiá»‡n khuÃ´n máº·t
    boxes, probs, landmarks_all = mtcnn.detect(img, landmarks=True)

    if boxes is None:
        st.error("âŒ KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c khuÃ´n máº·t!")
        st.stop()

    # Crop khuÃ´n máº·t Ä‘áº§u tiÃªn
    x1, y1, x2, y2 = boxes[0]
    face_pil = img.crop((x1, y1, x2, y2)).resize((160, 160))

    # Váº½ khung lÃªn áº£nh gá»‘c
    draw = ImageDraw.Draw(img)
    draw.rectangle([x1, y1, x2, y2], outline="red", width=3)
    st.image(img, caption="ğŸ“¸ áº¢nh gá»‘c (Ä‘Ã£ phÃ¡t hiá»‡n khuÃ´n máº·t)", use_container_width=True)

    # Hiá»ƒn thá»‹ áº£nh khuÃ´n máº·t cáº¯t ra
    st.image(face_pil, caption="ğŸ§© KhuÃ´n máº·t tá»± cáº¯t ra", width=200)

    # Embedding khuÃ´n máº·t truy váº¥n
    face_tensor = torch.tensor(np.array(face_pil)).permute(2, 0, 1).float() / 255.0
    face_tensor = (face_tensor.unsqueeze(0).to(device) * 2) - 1
    query_emb = resnet(face_tensor).detach().cpu().numpy().flatten()

    # So khá»›p vá»›i database
    D, I = index.search(query_emb.astype('float32').reshape(1, -1), 1)
    matched_path = filenames[I[0][0]]
    distance = float(D[0][0])
    person_name = os.path.splitext(os.path.basename(matched_path))[0]

    threshold = 0.9  # cÃ³ thá»ƒ tinh chá»‰nh

    # TÃ­nh embedding áº£nh khá»›p Ä‘á»ƒ so sÃ¡nh (resize áº£nh trong DB thÃ nh 160x160)
    try:
        matched_img_pil = Image.open(matched_path).convert("RGB").resize((160, 160))
        matched_tensor = torch.tensor(np.array(matched_img_pil)).permute(2, 0, 1).float() / 255.0
        matched_tensor = (matched_tensor.unsqueeze(0).to(device) * 2) - 1
        matched_emb = resnet(matched_tensor).detach().cpu().numpy().flatten()
    except Exception as e:
        matched_emb = None
        st.warning(f"âš ï¸ KhÃ´ng thá»ƒ má»Ÿ áº£nh Ä‘á»ƒ so sÃ¡nh embedding: {e}")

    # Hiá»ƒn thá»‹ káº¿t quáº£
    if distance < threshold:
        st.success(f"âœ… Khá»›p vá»›i: **{person_name}** (Khoáº£ng cÃ¡ch: {distance:.4f})")
        st.image(Image.open(matched_path), caption=f"áº¢nh trong database ({person_name})", width=200)
    else:
        st.warning(f"âš ï¸ KhÃ´ng khá»›p vá»›i ai trong database (Khoáº£ng cÃ¡ch: {distance:.4f})")

    # Váº½ Ä‘á»“ thá»‹ so sÃ¡nh 20 vector Ä‘áº§u tiÃªn náº¿u cÃ³ matched_emb
    if matched_emb is not None:
        plot_embedding_comparison(query_emb, matched_emb)
